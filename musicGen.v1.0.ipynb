{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from music21 import *\n",
    "import os\n",
    "import time\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "filenames = os.listdir(\"./maestro-v2.0.0/2018\")[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MIDI-Unprocessed_Chamber1_MID--AUDIO_07_R3_2018_wav--2.midi',\n",
       " 'MIDI-Unprocessed_Chamber2_MID--AUDIO_09_R3_2018_wav--1.midi',\n",
       " 'MIDI-Unprocessed_Chamber2_MID--AUDIO_09_R3_2018_wav--3.midi',\n",
       " 'MIDI-Unprocessed_Chamber3_MID--AUDIO_10_R3_2018_wav--1.midi',\n",
       " 'MIDI-Unprocessed_Chamber3_MID--AUDIO_10_R3_2018_wav--2.midi',\n",
       " 'MIDI-Unprocessed_Chamber3_MID--AUDIO_10_R3_2018_wav--3.midi',\n",
       " 'MIDI-Unprocessed_Chamber4_MID--AUDIO_11_R3_2018_wav--1.midi',\n",
       " 'MIDI-Unprocessed_Chamber4_MID--AUDIO_11_R3_2018_wav--3.midi',\n",
       " 'MIDI-Unprocessed_Chamber5_MID--AUDIO_18_R3_2018_wav--1.midi',\n",
       " 'MIDI-Unprocessed_Chamber5_MID--AUDIO_18_R3_2018_wav--2.midi']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parseMidi(list_filenames):\n",
    "    print(\"Loading samples.....\")\n",
    "    samples = [converter.parse(path + \"/maestro-v2.0.0/2018/\" + str(file)) for file in tqdm(list_filenames)]\n",
    "    sam_mono = [sample.chordify() for sample in tqdm(samples) if len(instrument.partitionByInstrument(sample).parts) == 1]\n",
    "    print(\"Samples loaded and chordified.....\")\n",
    "    list_chords = [[] for _ in sam_mono]\n",
    "    list_durations = [[] for _ in sam_mono]\n",
    "    list_keys = [[]]\n",
    "    print(\"Preparing data....\")\n",
    "    for i, song in enumerate(sam_mono):\n",
    "        list_keys.append(song.analyze(\"key\"))\n",
    "        for element in song:\n",
    "            if isinstance(element, note.Note):\n",
    "                list_chords[i].append(element.pitch)\n",
    "                list_durations[i].append(element.duration.quarterLength)\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                list_chords[i].append(\".\".join(str(n) for n in element.pitches))\n",
    "                list_durations[i].append(element.duration.quarterLength)\n",
    "    return list_chords, list_durations, list_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading samples.....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f92e7eb2403648df826ab32514278172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7e64c9085e04675a070e8d721ae0a7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples loaded and chordified.....\n",
      "Preparing data....\n"
     ]
    }
   ],
   "source": [
    "list_chords, list_durations, list_keys = _parseMidi(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20285\n",
      "79\n"
     ]
    }
   ],
   "source": [
    "#Find the number of unique Chords\n",
    "unique_chords = np.unique([i for s in list_chords for i in s])\n",
    "print(len(unique_chords))\n",
    "chord_to_int = dict(zip(unique_chords, range(0, len(unique_chords))))\n",
    "#Find the number of unique durations\n",
    "unique_durations = np.unique([i for s in list_durations for i in s])\n",
    "print(len(unique_durations))\n",
    "duration_to_int = dict(zip(unique_durations, range(0, len(unique_durations))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the reverse dict\n",
    "int_to_chord = {i:j for j, i in chord_to_int.items()}\n",
    "int_to_durations = {i:j for j, i in duration_to_int.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sequence length\n",
    "sequence_length = 32\n",
    "\n",
    "# Define the empty lists\n",
    "train_chords = []\n",
    "train_durations = []\n",
    "target_chords = []\n",
    "target_durations = []\n",
    "\n",
    "#Genrate the train and the target data\n",
    "for i in range(len(list_chords)):\n",
    "    chordList = [chord_to_int[chord] for chord in list_chords[i]]\n",
    "    durationList = [duration_to_int[chord] for chord in list_durations[i]]\n",
    "    for j in range(len(chordList) - sequence_length - 1):\n",
    "        train_chords.append(chordList[j:j + sequence_length])\n",
    "        train_durations.append(durationList[j:j + sequence_length])\n",
    "        target_chords.append(chordList[j + sequence_length + 1])\n",
    "        target_durations.append(durationList[j + sequence_length + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_chords = np.asarray(train_chords)\n",
    "train_durations = np.asarray(train_durations)\n",
    "target_chords = np.asarray(target_chords)\n",
    "target_durations = np.asarray(target_durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83874, 32)\n",
      "(83874, 32)\n",
      "(83874,)\n",
      "(83874,)\n"
     ]
    }
   ],
   "source": [
    "print(train_chords.shape)\n",
    "print(train_durations.shape)\n",
    "print(target_chords.shape)\n",
    "print(target_durations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_chords = to_categorical(target_chords)\n",
    "target_durations = to_categorical(target_durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83874, 20285)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_chords.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, *kwargs):\n",
    "        super(BahdanauAttention, self).__init__(*kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        # eg. input shape = (64, 512, 1024)\n",
    "        self.W = self.add_weight(name = 'att_weight', shape = (input_shape[-1], 1), initializer=\"normal\")\n",
    "        self.b = self.add_weight(name = 'att_bias', shape = (input_shape[1], 1), initializer=\"normal\")\n",
    "        super(BahdanauAttention, self).build(input_shape)\n",
    "    \n",
    "    def call(self, x):\n",
    "        et = K.tanh(K.dot(x, self.W) + self.b)\n",
    "        et = K.softmax(K.squeeze(et, axis = -1))\n",
    "        at = K.expand_dims(et, axis = -1)\n",
    "        output = x * at\n",
    "        return K.sum(output, axis = 1)\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[-1])\n",
    "    \n",
    "    def get_config(self):\n",
    "        return super(BahdanauAttention,self).get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input layers\n",
    "chord_input = tf.keras.layers.Input((sequence_length,))\n",
    "duration_input = tf.keras.layers.Input((sequence_length,))\n",
    "\n",
    "# Embedding layers\n",
    "embedding_chord = tf.keras.layers.Embedding(input_dim=len(chord_to_int), output_dim=embed_dim,\n",
    "                                            input_length=sequence_length)(chord_input)\n",
    "embedding_durations = tf.keras.layers.Embedding(input_dim=len(duration_to_int), output_dim=embed_dim, \n",
    "                                               input_length=sequence_length)(duration_input)\n",
    "\n",
    "# Concat these 2 layers\n",
    "concat = tf.keras.layers.Concatenate(axis = 1)([embedding_chord, embedding_durations])\n",
    "\n",
    "# Define the single LSTM layer with 512 units\n",
    "lstm_layer = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(512, return_sequences=True))(concat)\n",
    "\n",
    "lstm_layer2 = tf.keras.layers.LSTM(512, return_sequences=True)(lstm_layer)\n",
    "\n",
    "attention = BahdanauAttention()(lstm_layer2)\n",
    "\n",
    "flatten = tf.keras.layers.Flatten()(attention)\n",
    "\n",
    "# Define the intermediate dense layer\n",
    "dense = tf.keras.layers.Dense(256)(flatten)\n",
    "\n",
    "# Define the final output layers\n",
    "dense1 = tf.keras.layers.Dense(len(chord_to_int), activation = \"softmax\")(dense)\n",
    "dense2 = tf.keras.layers.Dense(len(duration_to_int), activation = \"softmax\")(dense)\n",
    "\n",
    "# Define the model \n",
    "model = tf.keras.models.Model([chord_input, duration_input], [dense1, dense2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 32)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 32, 64)       1298240     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 32, 64)       5056        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 64, 64)       0           embedding[0][0]                  \n",
      "                                                                 embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 64, 1024)     2363392     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 64, 512)      3147776     bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bahdanau_attention (BahdanauAtt (None, 512)          576         lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 512)          0           bahdanau_attention[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          131328      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 20285)        5213245     dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 79)           20303       dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 12,179,916\n",
      "Trainable params: 12,179,916\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 83874 samples\n",
      "Epoch 1/30\n",
      "83874/83874 [==============================] - 131s 2ms/sample - loss: 10.3138 - dense_1_loss: 8.5350 - dense_2_loss: 1.7786\n",
      "Epoch 2/30\n",
      "83874/83874 [==============================] - 123s 1ms/sample - loss: 9.9552 - dense_1_loss: 8.2462 - dense_2_loss: 1.7089s - loss: 9.9567 - den\n",
      "Epoch 3/30\n",
      "83874/83874 [==============================] - 122s 1ms/sample - loss: 9.8418 - dense_1_loss: 8.1407 - dense_2_loss: 1.7009\n",
      "Epoch 4/30\n",
      "83874/83874 [==============================] - 123s 1ms/sample - loss: 9.7534 - dense_1_loss: 8.0550 - dense_2_loss: 1.6986\n",
      "Epoch 5/30\n",
      "83874/83874 [==============================] - 123s 1ms/sample - loss: 9.6531 - dense_1_loss: 7.9676 - dense_2_loss: 1.6855\n",
      "Epoch 6/30\n",
      "83874/83874 [==============================] - 123s 1ms/sample - loss: 9.5442 - dense_1_loss: 7.8776 - dense_2_loss: 1.6664\n",
      "Epoch 7/30\n",
      "83874/83874 [==============================] - 124s 1ms/sample - loss: 9.4415 - dense_1_loss: 7.8065 - dense_2_loss: 1.6354\n",
      "Epoch 8/30\n",
      "83874/83874 [==============================] - 124s 1ms/sample - loss: 9.3401 - dense_1_loss: 7.7383 - dense_2_loss: 1.6020\n",
      "Epoch 9/30\n",
      "83874/83874 [==============================] - 123s 1ms/sample - loss: 9.2933 - dense_1_loss: 7.7271 - dense_2_loss: 1.5660\n",
      "Epoch 10/30\n",
      "83874/83874 [==============================] - 123s 1ms/sample - loss: 9.3902 - dense_1_loss: 7.8668 - dense_2_loss: 1.5232\n",
      "Epoch 11/30\n",
      "83874/83874 [==============================] - 123s 1ms/sample - loss: 9.8172 - dense_1_loss: 8.3612 - dense_2_loss: 1.4555s - loss: 9.8101 - dense_1_loss: 8.3541 \n",
      "Epoch 12/30\n",
      "83874/83874 [==============================] - 124s 1ms/sample - loss: 10.2549 - dense_1_loss: 8.8563 - dense_2_loss: 1.3988\n",
      "Epoch 13/30\n",
      "83874/83874 [==============================] - 123s 1ms/sample - loss: 10.2701 - dense_1_loss: 8.9186 - dense_2_loss: 1.3515\n",
      "Epoch 14/30\n",
      "83874/83874 [==============================] - 123s 1ms/sample - loss: 10.1771 - dense_1_loss: 8.8900 - dense_2_loss: 1.2872 - loss: 10.1749 -\n",
      "Epoch 15/30\n",
      "83874/83874 [==============================] - 123s 1ms/sample - loss: 10.0846 - dense_1_loss: 8.8667 - dense_2_loss: 1.2185\n",
      "Epoch 16/30\n",
      "83874/83874 [==============================] - 123s 1ms/sample - loss: 9.9736 - dense_1_loss: 8.8298 - dense_2_loss: 1.1434\n",
      "Epoch 17/30\n",
      "83874/83874 [==============================] - 123s 1ms/sample - loss: 9.8610 - dense_1_loss: 8.8053 - dense_2_loss: 1.0562\n",
      "Epoch 18/30\n",
      "83874/83874 [==============================] - 124s 1ms/sample - loss: 9.7569 - dense_1_loss: 8.7900 - dense_2_loss: 0.9671\n",
      "Epoch 19/30\n",
      "83874/83874 [==============================] - 124s 1ms/sample - loss: 9.6586 - dense_1_loss: 8.7807 - dense_2_loss: 0.8783s - loss: 9.6532 - dense_1_loss: 8.7766\n",
      "Epoch 20/30\n",
      "83874/83874 [==============================] - 124s 1ms/sample - loss: 9.5468 - dense_1_loss: 8.7612 - dense_2_loss: 0.7856\n",
      "Epoch 21/30\n",
      "83874/83874 [==============================] - 124s 1ms/sample - loss: 9.4415 - dense_1_loss: 8.7444 - dense_2_loss: 0.6971\n",
      "Epoch 22/30\n",
      "83874/83874 [==============================] - 124s 1ms/sample - loss: 9.3321 - dense_1_loss: 8.7160 - dense_2_loss: 0.6164\n",
      "Epoch 23/30\n",
      "83874/83874 [==============================] - 124s 1ms/sample - loss: 9.2375 - dense_1_loss: 8.6945 - dense_2_loss: 0.5432\n",
      "Epoch 24/30\n",
      "83874/83874 [==============================] - 123s 1ms/sample - loss: 9.1327 - dense_1_loss: 8.6514 - dense_2_loss: 0.4813s - loss: 9.1265 - dense_1_loss: 8.64\n",
      "Epoch 25/30\n",
      "83874/83874 [==============================] - 124s 1ms/sample - loss: 9.0352 - dense_1_loss: 8.6106 - dense_2_loss: 0.42461s - - ETA: 0s - loss: 9.0350 - dense_1_loss: 8.6105 - dense_2_lo\n",
      "Epoch 26/30\n",
      "83874/83874 [==============================] - 124s 1ms/sample - loss: 8.9578 - dense_1_loss: 8.5731 - dense_2_loss: 0.3843\n",
      "Epoch 27/30\n",
      "83874/83874 [==============================] - 124s 1ms/sample - loss: 8.8861 - dense_1_loss: 8.5320 - dense_2_loss: 0.3536s - loss: 8.8771\n",
      "Epoch 28/30\n",
      "83874/83874 [==============================] - 123s 1ms/sample - loss: 8.8170 - dense_1_loss: 8.4957 - dense_2_loss: 0.3217s - loss: 8.8177 - d\n",
      "Epoch 29/30\n",
      "83874/83874 [==============================] - 124s 1ms/sample - loss: 8.7494 - dense_1_loss: 8.4516 - dense_2_loss: 0.2978\n",
      "Epoch 30/30\n",
      "83874/83874 [==============================] - 124s 1ms/sample - loss: 8.6945 - dense_1_loss: 8.4164 - dense_2_loss: 0.2778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x272a10c6da0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss = \"categorical_crossentropy\", optimizer = \"rmsprop\")\n",
    "model.fit([train_chords, train_durations], [target_chords, target_durations], batch_size=64, epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"att_modelv1.0.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(n_samples):\n",
    "    def predict_next(chord_seq, dur_seq):\n",
    "        out_chord, out_dur = model.predict([chord_seq, dur_seq])\n",
    "        return out_chord, out_dur\n",
    "    \n",
    "    def make_predictions(num_steps, init_chord, init_dur, model):\n",
    "        for i in range(num_steps):\n",
    "            chord, dur = predict_next(np.asarray(init_chord[-32:]).reshape(1,-1), np.asarray(init_dur[-32:]).reshape(1,-1))\n",
    "            chord_out = np.argmax(chord)\n",
    "            dur_out = np.argmax(dur)\n",
    "            init_chord.append(chord_out)\n",
    "            init_dur.append(dur_out)\n",
    "        return init_chord[32:], init_dur[32:]\n",
    "    \n",
    "    for n in tqdm(range(n_samples)):\n",
    "        seed = np.random.randint(low = 0, high = train_chords.shape[0])\n",
    "        CHORD, DURATION = make_predictions(100, train_chords[seed].tolist(), train_durations[seed].tolist(), model)\n",
    "        CHORD = [int_to_chord[c] for c in CHORD]\n",
    "        DURATION = [int_to_durations[d] for d in DURATION]\n",
    "        generated_stream = stream.Stream()\n",
    "        generated_stream.append(instrument.Piano())\n",
    "        for i in range(len(CHORD)):\n",
    "            try:\n",
    "                generated_stream.append(note.Note(CHORD[i].replace(\".\", \" \"), quaterType = DURATION[i]))\n",
    "            except:\n",
    "                generated_stream.append(chord.Chord(CHORD[i].replace(\".\", \" \"), quaterType = DURATION[i]))\n",
    "        generated_stream.write('midi', fp=path+'/generated/song{0}.mid'.format(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecdc3f047d05456f852967403fe34e8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate_samples(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
