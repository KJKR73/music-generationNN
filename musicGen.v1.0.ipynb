{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from music21 import *\n",
    "import os\n",
    "import time\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tqdm.notebook import tqdm\n",
    "from fractions import Fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "filenames = os.listdir(\"./maestro-v2.0.0/2018\")[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MIDI-Unprocessed_Chamber1_MID--AUDIO_07_R3_2018_wav--2.midi',\n",
       " 'MIDI-Unprocessed_Chamber2_MID--AUDIO_09_R3_2018_wav--1.midi',\n",
       " 'MIDI-Unprocessed_Chamber2_MID--AUDIO_09_R3_2018_wav--3.midi',\n",
       " 'MIDI-Unprocessed_Chamber3_MID--AUDIO_10_R3_2018_wav--1.midi',\n",
       " 'MIDI-Unprocessed_Chamber3_MID--AUDIO_10_R3_2018_wav--2.midi',\n",
       " 'MIDI-Unprocessed_Chamber3_MID--AUDIO_10_R3_2018_wav--3.midi',\n",
       " 'MIDI-Unprocessed_Chamber4_MID--AUDIO_11_R3_2018_wav--1.midi',\n",
       " 'MIDI-Unprocessed_Chamber4_MID--AUDIO_11_R3_2018_wav--3.midi',\n",
       " 'MIDI-Unprocessed_Chamber5_MID--AUDIO_18_R3_2018_wav--1.midi',\n",
       " 'MIDI-Unprocessed_Chamber5_MID--AUDIO_18_R3_2018_wav--2.midi',\n",
       " 'MIDI-Unprocessed_Chamber6_MID--AUDIO_20_R3_2018_wav--1.midi',\n",
       " 'MIDI-Unprocessed_Chamber6_MID--AUDIO_20_R3_2018_wav--2.midi',\n",
       " 'MIDI-Unprocessed_Chamber6_MID--AUDIO_20_R3_2018_wav--3.midi',\n",
       " 'MIDI-Unprocessed_Recital1-3_MID--AUDIO_01_R1_2018_wav--1.midi',\n",
       " 'MIDI-Unprocessed_Recital1-3_MID--AUDIO_01_R1_2018_wav--2.midi',\n",
       " 'MIDI-Unprocessed_Recital1-3_MID--AUDIO_01_R1_2018_wav--3.midi',\n",
       " 'MIDI-Unprocessed_Recital1-3_MID--AUDIO_01_R1_2018_wav--4.midi',\n",
       " 'MIDI-Unprocessed_Recital1-3_MID--AUDIO_02_R1_2018_wav--1.midi',\n",
       " 'MIDI-Unprocessed_Recital1-3_MID--AUDIO_02_R1_2018_wav--2.midi',\n",
       " 'MIDI-Unprocessed_Recital1-3_MID--AUDIO_02_R1_2018_wav--3.midi']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parseMidi(list_filenames):\n",
    "    print(\"Loading samples.....\")\n",
    "    samples = [converter.parse(path + \"/maestro-v2.0.0/2018/\" + str(file)) for file in tqdm(list_filenames)]\n",
    "    sam_mono = [sample.chordify() for sample in tqdm(samples) if len(instrument.partitionByInstrument(sample).parts) == 1]\n",
    "    print(\"Samples loaded and chordified.....\")\n",
    "    list_chords = [[] for _ in sam_mono]\n",
    "    list_durations = [[] for _ in sam_mono]\n",
    "    list_keys = [[]]\n",
    "    print(\"Preparing data....\")\n",
    "    for i, song in enumerate(sam_mono):\n",
    "        list_keys.append(song.analyze(\"key\"))\n",
    "        for element in song:\n",
    "            if isinstance(element, note.Note):\n",
    "                list_chords[i].append(element.pitch)\n",
    "                list_durations[i].append(element.duration.quarterLength)\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                list_chords[i].append(\".\".join(str(n) for n in element.pitches))\n",
    "                list_durations[i].append(element.duration.quarterLength)\n",
    "    return list_chords, list_durations, list_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading samples.....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cadcd560b2b64e1fae150cdc2a816b8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb3f40f7ae74b439485c76648476af2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples loaded and chordified.....\n",
      "Preparing data....\n"
     ]
    }
   ],
   "source": [
    "list_chords, list_durations, list_keys = _parseMidi(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156831"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([len(i) for i in list_chords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36386\n",
      "89\n"
     ]
    }
   ],
   "source": [
    "#Find the number of unique Chords\n",
    "unique_chords = np.unique([i for s in list_chords for i in s])\n",
    "print(len(unique_chords))\n",
    "chord_to_int = dict(zip(unique_chords, range(0, len(unique_chords))))\n",
    "#Find the number of unique durations\n",
    "unique_durations = np.unique([i for s in list_durations for i in s])\n",
    "print(len(unique_durations))\n",
    "duration_to_int = dict(zip(unique_durations, range(0, len(unique_durations))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the reverse dict\n",
    "int_to_chord = {i:j for j, i in chord_to_int.items()}\n",
    "int_to_durations = {i:j for j, i in duration_to_int.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sequence length\n",
    "sequence_length = 32\n",
    "\n",
    "# Define the empty lists\n",
    "train_chords = []\n",
    "train_durations = []\n",
    "target_chords = []\n",
    "target_durations = []\n",
    "\n",
    "#Genrate the train and the target data\n",
    "for i in range(len(list_chords)):\n",
    "    chordList = [chord_to_int[chord] for chord in list_chords[i]]\n",
    "    durationList = [duration_to_int[chord] for chord in list_durations[i]]\n",
    "    for j in range(len(chordList) - sequence_length - 1):\n",
    "        train_chords.append(chordList[j:j + sequence_length])\n",
    "        train_durations.append(durationList[j:j + sequence_length])\n",
    "        target_chords.append(chordList[j + sequence_length + 1])\n",
    "        target_durations.append(durationList[j + sequence_length + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_chords = np.asarray(train_chords)\n",
    "train_durations = np.asarray(train_durations)\n",
    "target_chords = np.asarray(target_chords)\n",
    "target_durations = np.asarray(target_durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156171, 32)\n",
      "(156171, 32)\n",
      "(156171,)\n",
      "(156171,)\n"
     ]
    }
   ],
   "source": [
    "print(train_chords.shape)\n",
    "print(train_durations.shape)\n",
    "print(target_chords.shape)\n",
    "print(target_durations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_chords = to_categorical(target_chords)\n",
    "target_durations = to_categorical(target_durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156171, 36386)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_chords.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, *kwargs):\n",
    "        super(BahdanauAttention, self).__init__(*kwargs)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        # eg. input shape = (64, 512, 1024)\n",
    "        self.W = self.add_weight(name = 'att_weight', shape = (input_shape[-1], 1), initializer=\"normal\")\n",
    "        self.b = self.add_weight(name = 'att_bias', shape = (input_shape[1], 1), initializer=\"normal\")\n",
    "        super(BahdanauAttention, self).build(input_shape)\n",
    "    \n",
    "    def call(self, x):\n",
    "        et = K.tanh(K.dot(x, self.W) + self.b)\n",
    "        et = K.softmax(K.squeeze(et, axis = -1))\n",
    "        at = K.expand_dims(et, axis = -1)\n",
    "        output = x * at\n",
    "        return K.sum(output, axis = 1)\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], input_shape[-1])\n",
    "    \n",
    "    def get_config(self):\n",
    "        return super(BahdanauAttention,self).get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input layers\n",
    "chord_input = tf.keras.layers.Input((sequence_length,))\n",
    "duration_input = tf.keras.layers.Input((sequence_length,))\n",
    "\n",
    "# Embedding layers\n",
    "embedding_chord = tf.keras.layers.Embedding(input_dim=len(chord_to_int), output_dim=embed_dim,\n",
    "                                            input_length=sequence_length)(chord_input)\n",
    "embedding_durations = tf.keras.layers.Embedding(input_dim=len(duration_to_int), output_dim=embed_dim, \n",
    "                                               input_length=sequence_length)(duration_input)\n",
    "\n",
    "# Concat these 2 layers\n",
    "concat = tf.keras.layers.Concatenate(axis = 1)([embedding_chord, embedding_durations])\n",
    "\n",
    "# Define the single LSTM layer with 512 units\n",
    "lstm_layer = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(512, return_sequences=True))(concat)\n",
    "\n",
    "lstm_layer2 = tf.keras.layers.LSTM(512, return_sequences=True)(lstm_layer)\n",
    "\n",
    "attention = BahdanauAttention()(lstm_layer2)\n",
    "\n",
    "flatten = tf.keras.layers.Flatten()(attention)\n",
    "\n",
    "# Define the intermediate dense layer\n",
    "dense = tf.keras.layers.Dense(256)(flatten)\n",
    "\n",
    "# Define the final output layers\n",
    "dense1 = tf.keras.layers.Dense(len(chord_to_int), activation = \"softmax\")(dense)\n",
    "dense2 = tf.keras.layers.Dense(len(duration_to_int), activation = \"softmax\")(dense)\n",
    "\n",
    "# Define the model \n",
    "model = tf.keras.models.Model([chord_input, duration_input], [dense1, dense2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 32)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 32, 64)       2328704     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 32, 64)       5696        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 64, 64)       0           embedding[0][0]                  \n",
      "                                                                 embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 64, 1024)     2363392     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 64, 512)      3147776     bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bahdanau_attention (BahdanauAtt (None, 512)          576         lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 512)          0           bahdanau_attention[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          131328      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 36386)        9351202     dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 89)           22873       dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 17,351,547\n",
      "Trainable params: 17,351,547\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 156171 samples\n",
      "Epoch 1/30\n",
      "156171/156171 [==============================] - 230s 1ms/sample - loss: 10.6495 - dense_1_loss: 8.9331 - dense_2_loss: 1.7153 - los\n",
      "Epoch 2/30\n",
      "156171/156171 [==============================] - 225s 1ms/sample - loss: 9.7102 - dense_1_loss: 8.0444 - dense_2_loss: 1.6656\n",
      "Epoch 3/30\n",
      "156171/156171 [==============================] - 233s 1ms/sample - loss: 8.9269 - dense_1_loss: 7.2778 - dense_2_loss: 1.6494\n",
      "Epoch 4/30\n",
      "156171/156171 [==============================] - 229s 1ms/sample - loss: 8.1500 - dense_1_loss: 6.5134 - dense_2_loss: 1.6371\n",
      "Epoch 5/30\n",
      "156171/156171 [==============================] - 228s 1ms/sample - loss: 7.3797 - dense_1_loss: 5.7556 - dense_2_loss: 1.6237\n",
      "Epoch 6/30\n",
      "156171/156171 [==============================] - 227s 1ms/sample - loss: 6.6865 - dense_1_loss: 5.0807 - dense_2_loss: 1.6053s - loss: \n",
      "Epoch 7/30\n",
      "156171/156171 [==============================] - 229s 1ms/sample - loss: 6.0954 - dense_1_loss: 4.5104 - dense_2_loss: 1.5855\n",
      "Epoch 8/30\n",
      "156171/156171 [==============================] - 221s 1ms/sample - loss: 5.5653 - dense_1_loss: 4.0061 - dense_2_loss: 1.5591- ETA: 14s - loss: 5.5434 - den - ETA: 11s - loss: 5.5492 - dense_1_lo - ETA: 6s - loss: 5.5564 - dense_\n",
      "Epoch 9/30\n",
      "156171/156171 [==============================] - 220s 1ms/sample - loss: 5.0292 - dense_1_loss: 3.5026 - dense_2_loss: 1.5273\n",
      "Epoch 10/30\n",
      "156171/156171 [==============================] - 224s 1ms/sample - loss: 4.4791 - dense_1_loss: 2.9930 - dense_2_loss: 1.48602s - los - ETA: 5s - loss: 4.4703 - dense_1_loss:\n",
      "Epoch 11/30\n",
      "156171/156171 [==============================] - 224s 1ms/sample - loss: 3.9248 - dense_1_loss: 2.4952 - dense_2_loss: 1.4302\n",
      "Epoch 12/30\n",
      "156171/156171 [==============================] - 225s 1ms/sample - loss: 3.3927 - dense_1_loss: 2.0330 - dense_2_loss: 1.3608\n",
      "Epoch 13/30\n",
      "156171/156171 [==============================] - 227s 1ms/sample - loss: 2.9069 - dense_1_loss: 1.6368 - dense_2_loss: 1.2700\n",
      "Epoch 14/30\n",
      "156171/156171 [==============================] - 219s 1ms/sample - loss: 2.4746 - dense_1_loss: 1.3138 - dense_2_loss: 1.1613\n",
      "Epoch 15/30\n",
      "156171/156171 [==============================] - 223s 1ms/sample - loss: 2.1089 - dense_1_loss: 1.0645 - dense_2_loss: 1.0445\n",
      "Epoch 16/30\n",
      "156171/156171 [==============================] - 227s 1ms/sample - loss: 1.7849 - dense_1_loss: 0.8677 - dense_2_loss: 0.9177\n",
      "Epoch 17/30\n",
      "156171/156171 [==============================] - 231s 1ms/sample - loss: 1.5254 - dense_1_loss: 0.7210 - dense_2_loss: 0.8052\n",
      "Epoch 18/30\n",
      "156171/156171 [==============================] - 220s 1ms/sample - loss: 1.3111 - dense_1_loss: 0.6097 - dense_2_loss: 0.7013s - loss: 1.3074 - dense_1_loss: 0.6073 - dense_2_loss: 0 - ETA: 1s - loss: 1.3085 - dense_1_loss: 0.6079 - dense_2_los\n",
      "Epoch 19/30\n",
      "156171/156171 [==============================] - 225s 1ms/sample - loss: 1.1356 - dense_1_loss: 0.5216 - dense_2_loss: 0.6141\n",
      "Epoch 20/30\n",
      "156171/156171 [==============================] - 228s 1ms/sample - loss: 1.0051 - dense_1_loss: 0.4648 - dense_2_loss: 0.5401\n",
      "Epoch 21/30\n",
      "156171/156171 [==============================] - 215s 1ms/sample - loss: 0.8952 - dense_1_loss: 0.4176 - dense_2_loss: 0.4779\n",
      "Epoch 22/30\n",
      "156171/156171 [==============================] - 221s 1ms/sample - loss: 0.8188 - dense_1_loss: 0.3840 - dense_2_loss: 0.4353\n",
      "Epoch 23/30\n",
      "156171/156171 [==============================] - 220s 1ms/sample - loss: 0.7422 - dense_1_loss: 0.3525 - dense_2_loss: 0.3898\n",
      "Epoch 24/30\n",
      "156171/156171 [==============================] - 230s 1ms/sample - loss: 0.6813 - dense_1_loss: 0.3262 - dense_2_loss: 0.3555\n",
      "Epoch 25/30\n",
      "156171/156171 [==============================] - 231s 1ms/sample - loss: 0.6402 - dense_1_loss: 0.3085 - dense_2_loss: 0.3321\n",
      "Epoch 26/30\n",
      "156171/156171 [==============================] - 225s 1ms/sample - loss: 0.6007 - dense_1_loss: 0.2927 - dense_2_loss: 0.3083\n",
      "Epoch 27/30\n",
      "156171/156171 [==============================] - 223s 1ms/sample - loss: 0.5611 - dense_1_loss: 0.2746 - dense_2_loss: 0.2867s - loss: 0.5541 - dens\n",
      "Epoch 28/30\n",
      "156171/156171 [==============================] - 229s 1ms/sample - loss: 0.5352 - dense_1_loss: 0.2621 - dense_2_loss: 0.2732\n",
      "Epoch 29/30\n",
      "156171/156171 [==============================] - 223s 1ms/sample - loss: 0.5193 - dense_1_loss: 0.2553 - dense_2_loss: 0.2639\n",
      "Epoch 30/30\n",
      "156171/156171 [==============================] - 225s 1ms/sample - loss: 0.4852 - dense_1_loss: 0.2413 - dense_2_loss: 0.2443\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21ba10eaa20>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss = \"categorical_crossentropy\", optimizer = 'adam')\n",
    "model.fit([train_chords, train_durations], [target_chords, target_durations], batch_size=128, epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"att_modelv1.76.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = model.load_weights('att_modelv1.0.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(n_samples):\n",
    "    def predict_next(chord_seq, dur_seq):\n",
    "        out_chord, out_dur = model.predict([chord_seq, dur_seq])\n",
    "        return out_chord, out_dur\n",
    "    \n",
    "    def make_predictions(num_steps, init_chord, init_dur, model):\n",
    "        for i in range(num_steps):\n",
    "            chord, dur = predict_next(np.asarray(init_chord[-32:]).reshape(1,-1), np.asarray(init_dur[-32:]).reshape(1,-1))\n",
    "            chord_out = np.argmax(chord)\n",
    "            dur_out = np.argmax(dur)\n",
    "            init_chord.append(chord_out)\n",
    "            init_dur.append(dur_out)\n",
    "        return init_chord[32:], init_dur[32:]\n",
    "    \n",
    "    for n in tqdm(range(n_samples)):\n",
    "        seed = np.random.randint(low = 0, high = train_chords.shape[0])\n",
    "        print(seed)\n",
    "        CHORD, DURATION = make_predictions(100, train_chords[seed].tolist(), train_durations[seed].tolist(), model)\n",
    "        CHORD = [int_to_chord[c] for c in CHORD]\n",
    "        DURATION = [int_to_durations[d] for d in DURATION]\n",
    "        generated_stream = stream.Stream()\n",
    "        generated_stream.append(instrument.Piano())\n",
    "        for i in range(len(CHORD)):\n",
    "            try:\n",
    "                generated_stream.append(note.Note(CHORD[i].replace(\".\", \" \"), quaterType = DURATION[i]))\n",
    "            except:\n",
    "                generated_stream.append(chord.Chord(CHORD[i].replace(\".\", \" \"), quaterType = DURATION[i]))\n",
    "        generated_stream.write('midi', fp=path+'/generated/song{0}.mid'.format(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa1275787b294ca5883b42f6993d81cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94445\n",
      "89370\n",
      "107298\n",
      "117446\n",
      "152680\n",
      "84609\n",
      "151124\n",
      "38587\n",
      "136957\n",
      "115915\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generate_samples(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
