{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from music21 import *\n",
    "import os\n",
    "import time\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "filenames = os.listdir(\"./data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parseMidi(list_filenames):\n",
    "    print(\"Loading samples.....\")\n",
    "    samples = [converter.parse(path + \"/data/\" + str(file)) for file in tqdm(list_filenames)]\n",
    "    sam_mono = [sample.chordify() for sample in tqdm(samples) if len(instrument.partitionByInstrument(sample).parts) == 1]\n",
    "    print(\"Samples loaded and chordified.....\")\n",
    "    list_chords = [[] for _ in sam_mono]\n",
    "    list_durations = [[] for _ in sam_mono]\n",
    "    list_keys = [[]]\n",
    "    print(\"Preparing data....\")\n",
    "    for i, song in enumerate(sam_mono):\n",
    "        list_keys.append(song.analyze(\"key\"))\n",
    "        for element in song:\n",
    "            if isinstance(element, note.Note):\n",
    "                list_chords[i].append(element.pitch)\n",
    "                list_durations[i].append(element.duration.quarterLength)\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                list_chords[i].append(\".\".join(str(n) for n in element.pitches))\n",
    "                list_durations[i].append(element.duration.quarterLength)\n",
    "    return list_chords, list_durations, list_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading samples.....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68fe841d032f4234a5bf5edca61aef2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=29.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fc4bef070be4c8b943a179fb19e977d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=29.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Samples loaded and chordified.....\n",
      "Preparing data....\n"
     ]
    }
   ],
   "source": [
    "list_chords, list_durations, list_keys = _parseMidi(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12632\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "#Find the number of unique Chords\n",
    "unique_chords = np.unique([i for s in list_chords for i in s])\n",
    "print(len(unique_chords))\n",
    "chord_to_int = dict(zip(unique_chords, range(0, len(unique_chords))))\n",
    "#Find the number of unique durations\n",
    "unique_durations = np.unique([i for s in list_durations for i in s])\n",
    "print(len(unique_durations))\n",
    "duration_to_int = dict(zip(unique_durations, range(0, len(unique_durations))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the reverse dict\n",
    "int_to_chord = {i:j for j, i in chord_to_int.items()}\n",
    "int_to_durations = {i:j for j, i in duration_to_int.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sequence length\n",
    "sequence_length = 32\n",
    "\n",
    "# Define the empty lists\n",
    "train_chords = []\n",
    "train_durations = []\n",
    "target_chords = []\n",
    "target_durations = []\n",
    "\n",
    "#Genrate the train and the target data\n",
    "for i in range(len(list_chords)):\n",
    "    chordList = [chord_to_int[chord] for chord in list_chords[i]]\n",
    "    durationList = [duration_to_int[chord] for chord in list_durations[i]]\n",
    "    for j in range(len(chordList) - sequence_length - 1):\n",
    "        train_chords.append(chordList[j:j + sequence_length])\n",
    "        train_durations.append(durationList[j:j + sequence_length])\n",
    "        target_chords.append(chordList[j + sequence_length + 1])\n",
    "        target_durations.append(durationList[j + sequence_length + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_chords = np.asarray(train_chords)\n",
    "train_durations = np.asarray(train_durations)\n",
    "target_chords = np.asarray(target_chords)\n",
    "target_durations = np.asarray(target_durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59365, 32)\n",
      "(59365, 32)\n",
      "(59365,)\n",
      "(59365,)\n"
     ]
    }
   ],
   "source": [
    "print(train_chords.shape)\n",
    "print(train_durations.shape)\n",
    "print(target_chords.shape)\n",
    "print(target_durations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_chords = to_categorical(target_chords)\n",
    "target_durations = to_categorical(target_durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input layers\n",
    "chord_input = tf.keras.layers.Input((None,))\n",
    "duration_input = tf.keras.layers.Input((None,))\n",
    "\n",
    "# Embedding layers\n",
    "embedding_chord = tf.keras.layers.Embedding(input_dim=len(chord_to_int), output_dim=embed_dim,\n",
    "                                            input_length=sequence_length)(chord_input)\n",
    "embedding_durations = tf.keras.layers.Embedding(input_dim=len(duration_to_int), output_dim=embed_dim, \n",
    "                                               input_length=sequence_length)(duration_input)\n",
    "\n",
    "# Concat these 2 layers\n",
    "concat = tf.keras.layers.Concatenate(axis = 1)([embedding_chord, embedding_durations])\n",
    "\n",
    "# Define the single LSTM layer with 512 units\n",
    "lstm_layer = tf.keras.layers.LSTM(512, return_sequences=True)(concat)\n",
    "\n",
    "lstm_layer2 = tf.keras.layers.LSTM(512)(lstm_layer)\n",
    "\n",
    "flatten = tf.keras.layers.Flatten()(lstm_layer2)\n",
    "\n",
    "# Define the intermediate dense layer\n",
    "dense = tf.keras.layers.Dense(256)(flatten)\n",
    "\n",
    "# Define the final output layers\n",
    "dense1 = tf.keras.layers.Dense(len(chord_to_int), activation = \"softmax\")(dense)\n",
    "dense2 = tf.keras.layers.Dense(len(duration_to_int), activation = \"softmax\")(dense)\n",
    "\n",
    "# Define the model \n",
    "model = tf.keras.models.Model([chord_input, duration_input], [dense1, dense2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_33 (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_34 (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_32 (Embedding)        (None, None, 64)     808448      input_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_33 (Embedding)        (None, None, 64)     1600        input_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, None, 64)     0           embedding_32[0][0]               \n",
      "                                                                 embedding_33[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_13 (LSTM)                  (None, None, 512)    1181696     concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lstm_14 (LSTM)                  (None, 512)          2099200     lstm_13[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 512)          0           lstm_14[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 256)          131328      flatten_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 12632)        3246424     dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 25)           6425        dense_23[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 7,475,121\n",
      "Trainable params: 7,475,121\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 59365 samples\n",
      "Epoch 1/20\n",
      "59365/59365 [==============================] - 57s 959us/sample - loss: 9.3823 - dense_24_loss: 8.4987 - dense_25_loss: 0.8836 - loss: 9.3971 - dense_24_loss: 8.5114 -\n",
      "Epoch 2/20\n",
      "59365/59365 [==============================] - 54s 916us/sample - loss: 7.8235 - dense_24_loss: 7.1358 - dense_25_loss: 0.6874\n",
      "Epoch 3/20\n",
      "59365/59365 [==============================] - 54s 917us/sample - loss: 6.3590 - dense_24_loss: 5.8003 - dense_25_loss: 0.5586\n",
      "Epoch 4/20\n",
      "59365/59365 [==============================] - 54s 918us/sample - loss: 5.1153 - dense_24_loss: 4.6679 - dense_25_loss: 0.4474\n",
      "Epoch 5/20\n",
      "59365/59365 [==============================] - 54s 916us/sample - loss: 4.1583 - dense_24_loss: 3.7944 - dense_25_loss: 0.3640\n",
      "Epoch 6/20\n",
      "59365/59365 [==============================] - 54s 914us/sample - loss: 3.4275 - dense_24_loss: 3.1369 - dense_25_loss: 0.2905 - loss: 3.4263 - dense_24_loss: \n",
      "Epoch 7/20\n",
      "59365/59365 [==============================] - 54s 914us/sample - loss: 2.8600 - dense_24_loss: 2.6270 - dense_25_loss: 0.2329\n",
      "Epoch 8/20\n",
      "59365/59365 [==============================] - 54s 917us/sample - loss: 2.4167 - dense_24_loss: 2.2259 - dense_25_loss: 0.1909\n",
      "Epoch 9/20\n",
      "59365/59365 [==============================] - 55s 921us/sample - loss: 2.0964 - dense_24_loss: 1.9346 - dense_25_loss: 0.1618\n",
      "Epoch 10/20\n",
      "59365/59365 [==============================] - 55s 924us/sample - loss: 1.7796 - dense_24_loss: 1.6483 - dense_25_loss: 0.1316\n",
      "Epoch 11/20\n",
      "59365/59365 [==============================] - 55s 923us/sample - loss: 1.5621 - dense_24_loss: 1.4461 - dense_25_loss: 0.1163\n",
      "Epoch 12/20\n",
      "59365/59365 [==============================] - 55s 921us/sample - loss: 1.3527 - dense_24_loss: 1.2588 - dense_25_loss: 0.0939\n",
      "Epoch 13/20\n",
      "59365/59365 [==============================] - 55s 923us/sample - loss: 1.2152 - dense_24_loss: 1.1279 - dense_25_loss: 0.0873\n",
      "Epoch 14/20\n",
      "59365/59365 [==============================] - 55s 924us/sample - loss: 1.0789 - dense_24_loss: 0.9995 - dense_25_loss: 0.0794 - loss: 1.0769 - dense_24_loss: 0\n",
      "Epoch 15/20\n",
      "59365/59365 [==============================] - 55s 923us/sample - loss: 0.9765 - dense_24_loss: 0.9001 - dense_25_loss: 0.0763\n",
      "Epoch 16/20\n",
      "59365/59365 [==============================] - 55s 920us/sample - loss: 0.8721 - dense_24_loss: 0.8036 - dense_25_loss: 0.0684\n",
      "Epoch 17/20\n",
      "59365/59365 [==============================] - 55s 924us/sample - loss: 0.7640 - dense_24_loss: 0.7061 - dense_25_loss: 0.0582\n",
      "Epoch 18/20\n",
      "59365/59365 [==============================] - 55s 928us/sample - loss: 0.7241 - dense_24_loss: 0.6645 - dense_25_loss: 0.0596\n",
      "Epoch 19/20\n",
      "59365/59365 [==============================] - 55s 926us/sample - loss: 0.6724 - dense_24_loss: 0.6123 - dense_25_loss: 0.0600\n",
      "Epoch 20/20\n",
      "59365/59365 [==============================] - 55s 922us/sample - loss: 0.5719 - dense_24_loss: 0.5204 - dense_25_loss: 0.0516 - loss: 0.5702 - dense_24_loss: 0.5188 - dense\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2663220ec50>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\")\n",
    "model.fit([train_chords, train_durations], [target_chords, target_durations], batch_size=64, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(n_samples):\n",
    "    def predict_next(chord_seq, dur_seq):\n",
    "        out_chord, out_dur = model.predict([chord_seq, dur_seq])\n",
    "        return out_chord, out_dur\n",
    "    \n",
    "    def make_predictions(num_steps, init_chord, init_dur, model):\n",
    "        for i in range(num_steps):\n",
    "            chord, dur = predict_next(np.asarray(init_chord[-31:]).reshape(1,-1), np.asarray(init_dur[-31:]).reshape(1,-1))\n",
    "            chord_out = np.argmax(chord)\n",
    "            dur_out = np.argmax(dur)\n",
    "            init_chord.append(chord_out)\n",
    "            init_dur.append(dur_out)\n",
    "        return init_chord[32:], init_dur[32:]\n",
    "    \n",
    "    for n in tqdm(range(n_samples)):\n",
    "        seed = np.random.randint(low = 0, high = train_chords.shape[0])\n",
    "        CHORD, DURATION = make_predictions(100, train_chords[seed].tolist(), train_durations[seed].tolist(), model)\n",
    "        CHORD = [int_to_chord[c] for c in CHORD]\n",
    "        DURATION = [int_to_durations[d] for d in DURATION]\n",
    "        generated_stream = stream.Stream()\n",
    "        generated_stream.append(instrument.Piano())\n",
    "        for i in range(len(CHORD)):\n",
    "            try:\n",
    "                generated_stream.append(note.Note(CHORD[i].replace(\".\", \" \"), quaterType = DURATION[i]))\n",
    "            except:\n",
    "                generated_stream.append(chord.Chord(CHORD[i].replace(\".\", \" \"), quaterType = DURATION[i]))\n",
    "        generated_stream.write('midi', fp=path+'/generated/song{0}.mid'.format(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b392390c76e4bdcaa07c5e0ab6890b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate_samples(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
